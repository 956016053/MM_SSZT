// 变量名改成 questions 以匹配你的程序逻辑
window.QuestionBank = [
  {
    "id": "choice-1",
    "type": "choice",
    "question": "下列关于弱人工智能（Narrow AI）的描述，正确的是？",
    "options": [
      "具备跨领域泛化能力，能处理各种未见过的复杂问题",
      "专为特定任务设计，无法超出设定领域工作",
      "在所有领域都超越人类智能的假设性存在",
      "已实现商业化应用，如钢铁侠的贾维斯"
    ],
    "answer": 1,
    "hint": "弱AI=单项冠军，别和全能管家搞混啦！",
    "explanation": "弱人工智能的核心定义是专为特定任务设计，缺乏跨领域泛化能力（对应选项B）。选项A和D描述的是通用人工智能（General AI），目前尚未实现；选项C描述的是超人工智能（Super AI），属于遥远未来的假设。典型案例包括Siri、Alexa、垃圾邮件过滤器，它们仅能完成特定领域的任务。"
  },
  {
    "id": "choice-2",
    "type": "choice",
    "question": "图灵测试的核心机制是以下哪项？",
    "options": [
      "让机器通过视觉识别区分人类和其他机器",
      "通过文本对话让询问者无法分辨人类与机器",
      "测试机器解决复杂数学问题的速度",
      "验证机器是否能自我繁殖和进化"
    ],
    "answer": 2,
    "hint": "AI界的“蒙眼盲测”，靠聊天骗人～",
    "explanation": "图灵测试由艾伦·图灵在1950年《计算机器与智能》中提出，核心是“模仿游戏”：询问者通过文本与人类和机器对话，若无法分辨二者，则机器通过测试（对应选项B）。选项A混淆了视觉识别与文本交互；选项C是早期AI的性能测试，与图灵测试无关；选项D描述的是自我进化能力，并非图灵测试的核心。该测试启发了聊天机器人和自然语言处理（NLP）的发展。"
  },
  {
    "id": "choice-3",
    "type": "choice",
    "question": "1956年达特茅斯会议的关键历史贡献是？",
    "options": [
      "提出首个神经网络数学模型",
      "正式确立“人工智能”为独立学科",
      "开发出第一台自动驾驶车",
      "证明机器可以击败国际象棋冠军"
    ],
    "answer": 1,
    "hint": "AI的“出生证明”，大佬们给新领域起名啦！",
    "explanation": "达特茅斯会议由约翰·麦卡锡等人发起，核心贡献是正式提出“人工智能”（AI）一词，确立其为独立学科（对应选项B）。选项A是1943年麦卡洛克-皮茨神经元的贡献；选项C是2005年Stanley自动驾驶车的成就；选项D是1997年深蓝的突破。该会议标志着AI从跨学科探索正式成为专门的研究领域。"
  },
  {
    "id": "choice-4",
    "type": "choice",
    "question": "符号主义AI（GOFAI）的核心特征不包括以下哪项？",
    "options": [
      "自上而下的规则驱动",
      "依赖显式的知识表示",
      "从数据中自动学习模式",
      "基于逻辑推理进行决策"
    ],
    "answer": 2,
    "hint": "符号主义=法条主义者，靠手册办事，不是靠刷题～",
    "explanation": "符号主义AI的核心特征是：自上而下（Top-down）、显式知识表示、基于规则推理（对应选项A、B、D）。选项C“从数据中自动学习模式”是机器学习（尤其是深度学习）的特征，与符号主义的“手动编码规则”形成对比。符号主义认为智能可简化为符号操作，就像“背熟规则手册”办事，缺乏自主学习能力。"
  },
  {
    "id": "choice-5",
    "type": "choice",
    "question": "第一次AI寒冬（1974-1980）的导火索不包括以下哪份报告？",
    "options": [
      "ALPAC报告（1966年）",
      "Lighthill报告（1973年）",
      "Feynman报告（1981年）",
      "批评机器翻译和AI不切实际的报告"
    ],
    "answer": 2,
    "hint": "Feynman是物理学家，和AI寒冬没关系哦～",
    "explanation": "第一次AI寒冬的导火索是1966年ALPAC报告（批评机器翻译）和1973年Lighthill报告（批评AI不切实际），导致资金削减（对应选项A、B、D）。选项C的Feynman报告（1981年）主要讨论纳米技术和计算物理，与AI寒冬无关，且时间线也晚于第一次AI寒冬。AI寒冬的核心成因还包括算力限制和常识缺失。"
  },
  {
    "id": "choice-6",
    "type": "choice",
    "question": "下列哪种学习方式属于“有老师辅导的刷题”模式？",
    "options": [
      "监督学习",
      "无监督学习",
      "强化学习",
      "深度学习"
    ],
    "answer": 0,
    "hint": "有老师批改对错，就是监督学习呀～",
    "explanation": "监督学习的核心是从“带标签”数据中学习输入到输出的映射关系，就像“有老师辅导的刷题”：老师（标签）告知对错，模型修正思路（对应选项A）。选项B无监督学习是“无人指导的分类”，从无标签数据中发现模式；选项C强化学习是“驯兽模式”，通过奖励/惩罚机制学习；选项D深度学习是机器学习的子集，并非独立的学习方式。监督学习的典型应用包括图像识别、垃圾邮件检测。"
  },
  {
    "id": "choice-7",
    "type": "choice",
    "question": "AlexNet（2012）的关键创新不包括以下哪项？",
    "options": [
      "Transformer架构",
      "ReLU激活函数",
      "GPU加速训练",
      "Dropout正则化"
    ],
    "answer": 0,
    "hint": "AlexNet是CNN王者，Transformer是后来的NLP大佬～",
    "explanation": "AlexNet的关键创新包括：8层深层架构（5卷积+3全连接）、ReLU激活函数（提升训练速度）、Dropout正则化（防止过拟合）、GPU实现（加速10倍）、数据增强（增加训练量）（对应选项B、C、D）。选项A的Transformer架构是2017年提出的，用于NLP任务（如LLMs），并非AlexNet的创新。AlexNet将图像分类错误率从26%降至15%，标志着深度学习时代的到来。"
  },
  {
    "id": "choice-8",
    "type": "choice",
    "question": "AlphaGo（2016）击败李世石的核心技术不包括以下哪项？",
    "options": [
      "深度强化学习",
      "自我对弈训练",
      "蒙特卡洛树搜索",
      "纯监督学习"
    ],
    "answer": 3,
    "hint": "AlphaGo会自己和自己下棋，不是只靠别人教～",
    "explanation": "AlphaGo的核心技术是深度强化学习（结合CNN和RL）、自我对弈（海量模拟棋局训练）、蒙特卡洛树搜索（优化决策）（对应选项A、B、C）。选项D“纯监督学习”错误，因为AlphaGo并非仅依赖人类棋谱的监督训练，而是通过自我对弈实现能力超越人类。该成就突破了单纯靠计算无法解决的直觉型决策难题，证明了深度学习在复杂任务中的潜力。"
  },
  {
    "id": "fill-1",
    "type": "fill",
    "question": "人工智能的核心能力包括获取信息（学习）、得出结论（______）、自我修正（反馈）、模式识别。",
    "answer": "推理",
    "hint": "学习是输入，推理是加工输出，像大脑思考的过程～",
    "explanation": "人工智能的四大核心能力对应人类智能的关键过程：学习（获取信息）、推理（基于信息得出结论）、反馈（自我修正）、模式识别（感知和分类信息）。这四个能力是AI系统模拟人类智能的基础，也是区分AI与普通程序的核心特征——普通程序仅能执行预设指令，而AI能通过这四大能力实现“类人思考”。"
  },
  {
    "id": "fill-2",
    "type": "fill",
    "question": "专家系统的架构由用户界面、______和知识库三部分组成，其中前者被称为“推理大脑”。",
    "answer": "规则引擎",
    "hint": "知识库是“参考书”，规则引擎是“解题思路”～",
    "explanation": "专家系统的核心架构包括：用户界面（与用户交互）、规则引擎（核心推理模块，相当于“推理大脑”，根据知识库中的规则进行决策）、知识库（存储特定领域的专家知识）。典型案例MYCIN（诊断细菌感染）和XCON（配置计算机系统）均采用该架构，其瓶颈在于知识获取困难（隐性知识难以转化为规则）和脆弱性（超出领域即失效）。"
  },
  {
    "id": "fill-3",
    "type": "fill",
    "question": "机器学习三大类中，______通过与环境交互的“奖励/惩罚”机制学习最优策略，典型应用包括游戏AI和机器人控制。",
    "answer": "强化学习",
    "hint": "像驯兽师训练动物，做对给奖励，做错给惩罚～",
    "explanation": "强化学习（Reinforcement Learning）的核心是智能体与环境交互，通过奖励信号（正反馈）和惩罚信号（负反馈）调整策略，最终学习到最优行为。与监督学习（依赖标签）、无监督学习（依赖数据结构）不同，强化学习强调“试错学习”。典型应用包括AlphaGo的自我对弈、自动驾驶中的路径规划、游戏AI的决策优化。"
  },
  {
    "id": "fill-4",
    "type": "fill",
    "question": "当代AI的四大新兴趋势包括多模态AI、高效AI、可信AI和______，后者追求更广泛的推理和迁移学习能力。",
    "answer": "通用智能",
    "hint": "终极目标是让AI成为“全能管家”，而非“单项冠军”～",
    "explanation": "AI未来四大趋势中，通用智能（General Intelligence）是核心目标之一，旨在实现人类水平的跨领域认知能力，让AI能像人一样理解、学习和处理各种未见过的复杂问题（如贾维斯）。目前AI仍处于弱人工智能阶段，通用智能尚未实现，需要突破常识推理、跨领域迁移学习等瓶颈。其他三大趋势分别解决：多模态AI（整合多种感官信息）、高效AI（降低算力成本）、可信AI（确保公平透明）。"
  },
  {
    "id": "qa-1",
    "type": "qa",
    "question": "简述人工智能三大层级（弱AI、通用AI、超AI）的核心定义及主要区别。",
    "answer": "1. 弱人工智能（Narrow AI）：专为特定任务设计，无跨领域泛化能力，仅能完成预设任务（如Siri、AlphaGo），是目前已实现的AI形态；2. 通用人工智能（General AI）：具备人类水平认知能力，能跨领域理解、学习和处理复杂问题（如贾维斯），目前仍处于理论研究阶段；3. 超人工智能（Super AI）：在所有领域超越人类智能的假设性存在，智力远超人类认知极限，属于遥远未来的推测。主要区别在于：①认知范围（特定领域vs跨领域vs全领域）；②能力水平（任务限定vs人类水平vs超人类水平）；③实现状态（已实现vs未实现vs假设性）。",
    "hint": "记住关键词：弱AI=单项冠军，通用AI=全能管家，超AI=神级存在～",
    "explanation": "AI三大层级的划分基于智能的“泛化能力”和“水平高度”，是理解AI发展阶段的核心框架。弱AI是当前技术主流，聚焦单一任务（如图像识别、语音助手），缺乏常识和自主决策能力；通用AI需要突破常识推理、跨领域学习等瓶颈，是AI研究的长期目标；超AI则是对未来智能的极端假设，涉及伦理、安全等深层问题。这一划分帮助避免对当前AI能力的过度高估（如认为弱AI具备意识）或低估（如忽视通用AI的发展潜力）。"
  },
  {
    "id": "qa-2",
    "type": "qa",
    "question": "分析第一次AI寒冬（1974-1980）的主要成因，并说明这些成因对当代AI发展的启示。",
    "answer": "第一次AI寒冬的主要成因包括：1. 算力限制：组合爆炸导致简单任务需指数级资源，硬件无法支撑；2. 常识缺失：机器缺乏背景知识和直觉，无法处理人类习以为常的琐事；3. 资金削减：ALPAC报告（批评机器翻译）和Lighthill报告（批评AI不切实际）导致信任破产，投资方撤资。对当代AI发展的启示：①平衡预期：避免过度炒作，客观看待技术边界；②重视基础设施：算力和数据是AI发展的关键，需持续投入硬件和数据建设；③突破核心瓶颈：常识推理、跨领域泛化等基础问题需长期攻关；④务实落地：聚焦具体场景的实用价值，避免追求“万能AI”。",
    "hint": "AI寒冬=理想丰满+硬件骨感+承诺落空，当代要“脚踏实地”～",
    "explanation": "第一次AI寒冬是AI发展史上的重要转折点，暴露了早期符号主义AI的局限性：依赖手动编码规则，无法应对复杂现实场景。其启示对当代AI仍有重要意义：①算力方面，摩尔定律和GPU/TPU的发展解决了早期算力不足问题，但高效AI仍需降低算力消耗；②数据方面，大数据时代为机器学习提供了充足“燃料”，但数据质量和隐私问题需重视；③技术路线方面，从“手动编码规则”转向“数据驱动学习”是范式转移的关键，证明了“学习优于手写”；④产业方面，AI应用需聚焦落地场景（如医疗、工业），避免脱离实际的“空中楼阁”。"
  },
  {
    "id": "qa-3",
    "type": "qa",
    "question": "说明机器学习与传统符号主义AI的核心差异，并分别列举机器学习的三大类型及其核心机制。",
    "answer": "一、核心差异：1. 技术路线：符号主义AI是“自上而下”的规则驱动（手动编码知识和逻辑），机器学习是“自下而上”的数据驱动（从数据中自动学习模式）；2. 知识表示：符号主义依赖显式的符号和规则，机器学习依赖隐式的模型参数；3. 泛化能力：符号主义仅能处理预设规则内的任务（脆弱性），机器学习具备一定的跨场景泛化能力；4. 学习方式：符号主义需人工更新规则，机器学习可自主从数据中迭代优化。二、机器学习三大类型及机制：1. 监督学习：从带标签数据中学习输入→输出的映射关系（如图像分类），核心是“有老师辅导的刷题”；2. 无监督学习：从无标签数据中发现隐藏结构（如聚类），核心是“无人指导的分类”；3. 强化学习：通过与环境交互的奖励/惩罚机制学习最优策略（如游戏AI），核心是“试错学习”。",
    "hint": "符号主义=背手册，机器学习=刷真题，三大类型=有老师、无老师、驯兽师～",
    "explanation": "符号主义AI与机器学习的差异本质是“规则驱动”与“数据驱动”的范式之争。符号主义在20世纪50-70年代主导AI领域，但因常识缺失和脆弱性陷入寒冬；机器学习（尤其是深度学习）在90年代后崛起，凭借数据和算力的支撑，在感知、生成等任务中取得突破。机器学习的三大类型覆盖了不同的学习场景：监督学习适用于有明确目标的任务（如预测、分类），无监督学习适用于探索数据结构（如用户分群），强化学习适用于动态决策场景（如机器人控制）。这一分类为AI应用提供了清晰的技术选型框架，是当代AI工程实践的基础。"
  },
  // 第二章——AI智能体
    {
      "id": "choice-1",
      "type": "choice",
      "question": "AI智能体的核心循环顺序正确的是？",
      "options": [
        "行动(Action) → 感知(Perception) → 思考(Thinking) → 循环(Loop)",
        "感知(Perception) → 思考(Thinking) → 行动(Action) → 循环(Loop)",
        "思考(Thinking) → 感知(Perception) → 行动(Action) → 循环(Loop)",
        "感知(Perception) → 行动(Action) → 思考(Thinking) → 循环(Loop)"
      ],
      "answer": 1,
      "hint": "先看再想后动手，像人类一样不冲动～",
      "explanation": "AI智能体的核心循环遵循“感知-思考-行动-循环”的逻辑（对应选项B）。感知是通过传感器获取环境信息（如眼睛看、耳朵听），思考是对感知信息进行决策分析，行动是通过执行器作用于环境，最后重复循环持续互动。选项A、C、D颠倒了感知、思考、行动的顺序，不符合智能体与环境交互的基本逻辑。例如吸尘器智能体先感知“当前位置是否脏”（感知），再决定“吸尘或移动”（思考），最后执行动作（行动），并持续循环。"
    },
    {
      "id": "choice-2",
      "type": "choice",
      "question": "下列哪种场景属于“部分可观测”环境？",
      "options": [
        "下象棋时观察棋盘所有棋子位置",
        "打扑克时看不到对手的手牌",
        "解数独时查看所有空白格子",
        "按照食谱步骤做菜"
      ],
      "answer": 1,
      "hint": "看不到全部信息=部分可观测，像猜盲盒～",
      "explanation": "部分可观测环境的定义是传感器无法检测到环境的所有状态（对应选项B）。打扑克时，玩家只能看到自己的牌，无法获取对手的手牌，属于部分可观测；选项A（下象棋）、C（解数独）能看到全部状态，属于完全可观测；选项D（按食谱做菜）属于确定性环境，与可观测性无关。环境的可观测性是智能体设计的重要前提，部分可观测环境需要智能体具备推理隐藏状态的能力。"
    },
    {
      "id": "choice-3",
      "type": "choice",
      "question": "PEAS设计框架中，“P”对应的核心要素是？",
      "options": [
        "Performance Measure（性能度量）",
        "Environment（环境）",
        "Perception（感知）",
        "Program（程序）"
      ],
      "answer": 0,
      "hint": "PEAS首字母P=Performance，成功的标准呀～",
      "explanation": "PEAS框架是智能体设计的核心四要素，分别对应：P（Performance Measure，性能度量，即成功的标准）、E（Environment，环境）、A（Actuators，执行器）、S（Sensors，传感器）（对应选项A）。选项B是“E”的含义，选项C是智能体核心循环的第一步，选项D并非PEAS框架的要素。例如出租车智能体的性能度量包括安全、快速、合法、利润最大化，直接决定智能体的行动优先级。"
    },
    {
      "id": "choice-4",
      "type": "choice",
      "question": "软件智能体与传统函数（Functions）的核心区别不包括？",
      "options": [
        "智能体具有状态维持能力，函数“算完就忘”",
        "智能体可自主决策行动时机，函数需被动调用",
        "智能体依赖数据驱动，函数依赖规则驱动",
        "智能体是“长寿”的持续运行实体，函数是“短命”的单次执行任务"
      ],
      "answer": 2,
      "hint": "核心区别是“长寿+自主+有记忆”，和驱动方式无关～",
      "explanation": "软件智能体与传统函数的核心区别包括：①状态维持（智能体有记忆，函数无）；②自主性（智能体主动行动，函数被动调用）；③生命周期（智能体持续运行，函数单次执行）（对应选项A、B、D）。选项C“数据驱动vs规则驱动”是机器学习与符号主义AI的区别，并非智能体与函数的差异——智能体和函数都可能是数据驱动或规则驱动（如规则型智能体、数据驱动型函数）。直观理解：函数像外卖员（送完即结束），智能体像私人管家（持续服务、记喜好）。"
    },
    {
      "id": "choice-5",
      "type": "choice",
      "question": "ReAct模式的核心逻辑顺序是？",
      "options": [
        "观察(Observation) → 思考(Thought) → 行动(Action) → 循环",
        "思考(Thought) → 观察(Observation) → 行动(Action) → 循环",
        "思考(Thought) → 行动(Action) → 观察(Observation) → 循环",
        "行动(Action) → 思考(Thought) → 观察(Observation) → 循环"
      ],
      "answer": 2,
      "hint": "先想思路，再动手做，最后看结果～ 像做题一样！",
      "explanation": "ReAct模式的核心逻辑是“思考-行动-观察-循环”（对应选项C）：①思考（明确目标和行动方向，如“需要查某公司营收”）；②行动（执行具体操作，如调用搜索工具）；③观察（获取行动结果，如搜索结果）；④循环（根据观察调整思考和行动）。该模式解决了大模型实时信息获取和“幻觉”问题，模拟人类解题的思维过程。选项A、B、D颠倒了思考、行动、观察的顺序，不符合ReAct的设计初衷。"
    },
    {
      "id": "choice-6",
      "type": "choice",
      "question": "RAG智能体（检索增强生成）的核心目的不包括？",
      "options": [
        "解决大模型“知识截止期”问题",
        "减少大模型的“幻觉”（一本正经胡说八道）",
        "降低模型的训练成本，无需重新训练",
        "提升模型的推理速度，减少计算资源消耗"
      ],
      "answer": 3,
      "hint": "RAG是“开卷考试”，补知识不提速～",
      "explanation": "RAG智能体的核心优势包括：①解决知识截止期（通过外挂知识库更新信息）；②减少幻觉（基于真实文档生成答案）；③无需重新训练（通过检索补充知识，降低训练成本）（对应选项A、B、C）。选项D“提升推理速度”并非RAG的核心目的，反而检索过程可能增加少量延迟。RAG的关键流程是“离线准备（文档切块→向量化→存入向量库）+在线检索（检索→增强→生成）”，本质是给大模型“开卷考试”的机会，而非优化速度。"
    },
    {
      "id": "choice-7",
      "type": "choice",
      "question": "下列哪项不属于Agentic AI的核心特征？",
      "options": [
        "极少的人类干预，高度自主",
        "仅能被动响应用户查询，无法主动决策",
        "能够处理多步复杂任务",
        "主动使用工具辅助完成目标"
      ],
      "answer": 1,
      "hint": "Agentic AI是“项目经理”，不是“问答机器”～",
      "explanation": "Agentic AI的核心特征包括：①高度自主性（极少人类干预）；②处理多步复杂任务；③主动使用工具（对应选项A、C、D）。选项B“被动响应查询”是传统聊天机器人的特征，与Agentic AI“主动决策、搞定过程”的定位相反。直观理解：Agentic AI从“我问你答”进化为“我说目标，你搞定过程”，例如自主帮用户订机票（需查询、对比、下单多步操作）。"
    },
    {
      "id": "choice-8",
      "type": "choice",
      "question": "思维树（Tree-of-Thoughts, ToT）模式的核心逻辑是？",
      "options": [
        "重复生成多个答案，选择出现次数最多的",
        "探索多条推理路径，预演后果后选择最优解",
        "生成草稿后自我评估并修改",
        "将任务拆解为子步骤，逐一执行并验证"
      ],
      "answer": 1,
      "hint": "像下棋预演几步，选最稳的走法～",
      "explanation": "思维树（ToT）模式的核心是探索多条推理路径，像下棋一样预演后续步骤，再选择最优解（对应选项B）。选项A是“自我一致性”模式的逻辑；选项C是“Reflexion”模式的逻辑；选项D是“计划-执行-验证”模式的逻辑。ToT解决了大模型单一推理路径易出错的问题，通过多路径探索提升复杂任务的成功率，例如数学解题、逻辑推理等场景。"
    },
    {
      "id": "fill-1",
      "type": "fill",
      "question": "AI智能体的官方定义是：任何通过______感知环境，并通过执行器作用于环境以实现目标的实体。",
      "answer": "传感器",
      "hint": "人类用眼睛耳朵感知，智能体用“电子感官”～",
      "explanation": "AI智能体的核心组成包括传感器（感知环境）和执行器（作用于环境）：传感器是智能体的“感官”，如摄像头、GPS、麦克风等，用于获取环境状态信息；执行器是智能体的“手脚”，如方向盘、机械臂、喇叭等，用于执行决策后的行动。该定义强调智能体与环境的交互能力，区别于单纯的静态模型（如仅生成文本的大模型）。"
    },
    {
      "id": "fill-2",
      "type": "fill",
      "question": "环境分类的六大维度中，______维度关注“当前决策是否影响未来决策”，对应的两类环境是片段式和序列式。",
      "answer": "片段式 vs 序列式",
      "hint": "这单干完是否影响下单？是就是序列式～",
      "explanation": "片段式 vs 序列式是环境分类的核心维度之一，核心判断标准是“当前决策是否影响未来决策”：片段式环境中，每个任务独立（如辨认单张照片），决策不影响后续；序列式环境中，当前决策会持续影响未来（如下围棋、开车），需考虑长期后果。该维度直接决定智能体的决策逻辑——序列式环境需要智能体具备长期规划和记忆能力。"
    },
    {
      "id": "fill-3",
      "type": "fill",
      "question": "Reflexion模式的核心流程是：生成草稿→______→根据评估修改→输出，通过“内部批评家”提升结果质量。",
      "answer": "自我评估",
      "hint": "像写作文自己先检查，改完再交～",
      "explanation": "Reflexion模式的核心是“自省与自纠”，通过增加自我评估环节解决大模型输出不精准的问题：①生成草稿（初步结果）；②自我评估（分析不足，如“逻辑不连贯”“数据错误”）；③修改优化（根据评估调整）；④输出最终结果。该模式模拟人类“复盘”行为，尤其适用于写作、解题等需要高精度输出的场景，能有效降低错误率。"
    },
    {
      "id": "fill-4",
      "type": "fill",
      "question": "RAG智能体的离线准备阶段包括文档切块、向量化和______三个关键步骤，为在线检索提供基础。",
      "answer": "存入向量数据库",
      "hint": "切好的“知识点”要放进专门的“数字书架”～",
      "explanation": "RAG智能体的离线准备阶段是实现高效检索的前提，三步流程缺一不可：①文档切块（将长文档拆分为短片段，便于精准匹配）；②向量化（将文本转化为计算机可理解的数字向量，捕捉语义信息）；③存入向量数据库（专门存储向量的数据库，支持快速相似性检索）。在线检索时，系统会将用户提问向量化后，在向量数据库中查找最相关的文本片段，再结合大模型生成答案，从而减少幻觉、更新知识。"
    },
    {
      "id": "fill-5",
      "type": "fill",
      "question": "多智能体协作模式的核心逻辑是让不同智能体扮演不同角色，像组建一个全AI的“______”，共同完成复杂任务。",
      "answer": "创业团队",
      "hint": "有人写代码、有人测Bug，分工合作效率高～",
      "explanation": "多智能体协作是Agentic AI的新兴设计模式之一，核心是“分工协作”：将复杂任务拆解为多个子任务，每个智能体负责特定角色（如编程智能体写代码、测试智能体查Bug、文档智能体写说明），像创业团队一样各司其职、协同完成目标。该模式解决了单一智能体能力边界有限的问题，适用于复杂项目（如自主研发、多步骤业务处理），提升任务完成的效率和质量。"
    },
    {
      "id": "qa-1",
      "type": "qa",
      "question": "简述AI智能体的核心定义、核心循环及数学表达，并举例说明经典的“吸尘器世界”智能体如何体现这些要素。",
      "answer": "1. 核心定义：任何通过传感器感知环境，并通过执行器作用于环境以实现目标的实体；2. 核心循环：感知(Perception) → 思考/决策(Thinking) → 行动(Action) → 循环(Loop)；3. 数学表达：$f: P^* \rightarrow A$（将感知历史序列$P^*$映射到行动$A$的函数）。举例：吸尘器世界智能体（两个方格A/B，状态“脏/干净”）：①感知：通过传感器获取“当前位置（A/B）”和“环境状态（脏/干净）”（如感知结果[A, Dirty]）；②思考：根据感知判断行动（脏则吸尘，干净则移动）；③行动：通过执行器执行吸尘、左移、右移等动作；④循环：持续感知环境变化，重复上述流程，最终实现“清洁所有方格”的目标。",
      "hint": "定义抓“传感器+执行器+目标”，循环记“看-想-做-循环”～",
      "explanation": "AI智能体的核心是“与环境的动态交互”，区别于静态模型（如计算器）：①定义强调“感知-行动”闭环，传感器和执行器是物理基础；②核心循环体现了智能体的自主性和持续性，而非单次响应；③数学表达抽象了智能体的本质——输入是历史感知信息，输出是具体行动。吸尘器世界是最简化的智能体案例，直观展示了“感知环境→决策→行动”的闭环，帮助理解复杂智能体的设计逻辑（如自动驾驶、机器人管家）的核心原理。"
    },
    {
      "id": "qa-2",
      "type": "qa",
      "question": "详细说明PEAS设计框架的四要素及其含义，并以“自主研究智能体”为例，逐一对应说明各要素的具体内容。",
      "answer": "PEAS框架是智能体设计的核心四要素，含义如下：1. P（Performance Measure，性能度量）：智能体成功的评价标准；2. E（Environment，环境）：智能体运行的外部空间及相关要素；3. A（Actuators，执行器）：智能体作用于环境的工具或手段；4. S（Sensors，传感器）：智能体感知环境的设备或渠道。以“自主研究智能体”为例：①性能度量：报告的准确性、信息的全面性、完成时间；②环境：互联网、学术数据库、文档管理系统；③执行器：浏览器（检索信息）、文本编辑器（写报告）、数据库查询工具（获取文献）；④传感器：网络爬虫（获取网页信息）、文献阅读器（读取学术论文）、关键词检索工具（筛选相关资料）。",
      "hint": "PEAS=成功标准+工作环境+干活工具+感知渠道，缺一不可～",
      "explanation": "PEAS框架是设计智能体的第一步，明确四要素能避免智能体设计的模糊性：①性能度量决定智能体的行动优先级（如自主研究智能体优先保证报告准确性，而非速度）；②环境定义了智能体的交互边界（如仅能访问公开学术数据库）；③执行器是智能体的“手脚”，决定了它能做什么（如能否编辑文档、调用工具）；④传感器是智能体的“感官”，决定了它能获取什么信息（如能否爬取网页、读取PDF）。该框架适用于所有智能体设计场景（如出租车、客服、编程智能体），是AI工程实践的基础工具。"
    },
    {
      "id": "qa-3",
      "type": "qa",
      "question": "对比ReAct、Reflexion、RAG三种LLM智能体架构的核心逻辑、解决痛点及适用场景，说明它们的本质区别。",
      "answer": "三种架构的核心差异如下：1. ReAct模式：①核心逻辑：思考(Thought)→行动(Action)→观察(Observation)→循环；②解决痛点：大模型无法获取实时信息、易产生幻觉；③适用场景：需要实时交互、调用工具的任务（如查实时数据、订机票）；2. Reflexion模式：①核心逻辑：生成草稿→自我评估→修改→输出；②解决痛点：大模型输出不精准、逻辑不连贯；③适用场景：需要高精度输出的任务（如写论文、解题）；3. RAG模式：①核心逻辑：离线准备（文档切块→向量化→存向量库）+在线检索（检索→增强→生成）；②解决痛点：大模型知识截止期、幻觉问题；③适用场景：需要最新知识、基于特定文档的任务（如企业知识库问答、学术研究）。本质区别：ReAct聚焦“与环境交互”，Reflexion聚焦“自我优化”，RAG聚焦“外部知识补充”，分别解决LLM在交互、精度、知识更新上的核心短板。",
      "hint": "ReAct=互动干活，Reflexion=自我纠错，RAG=开卷考试～",
      "explanation": "三种架构都是为了解决LLM的固有缺陷，但侧重点不同：①ReAct通过“思考-行动-观察”的闭环，让LLM具备与外部工具（如搜索引擎、API）交互的能力，突破了大模型“闭门造车”的限制；②Reflexion通过“自我评估-修改”的流程，让LLM具备复盘纠错能力，提升输出质量；③RAG通过外挂知识库，让LLM无需重新训练即可获取最新知识，同时减少幻觉（基于真实文档生成）。在实际应用中，三种架构可结合使用（如RAG+ReAct：检索知识后调用工具验证；Reflexion+RAG：基于检索到的资料生成答案后自我修正），形成更强大的智能体系统。"
    }
  
];